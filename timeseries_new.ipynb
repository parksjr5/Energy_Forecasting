{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries Analysis of Appliance and Light Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame the problem and look at the big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the report on this project in the [repository](https://github.com/parksjr5/Energy_Forecasting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = int(.8*df.shape[0])\n",
    "df_test, df_train = df[0:-nobs], df[-nobs:]\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create exploratory data\n",
    "exp_df = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute and Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "exp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "exp_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types of each column\n",
    "exp_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,5, figsize=(16,9))\n",
    "\n",
    "ax[0,0].plot(exp_df['date'].iloc[:100,], exp_df['T1'].iloc[:100,])\n",
    "ax[0,0].tick_params(labelbottom = False, bottom = False)\n",
    "ax[0,0].set_ylabel('Temperature')\n",
    "ax[1,0].plot(exp_df['date'].iloc[:100,], exp_df['RH_1'].iloc[:100,])\n",
    "ax[1,0].tick_params(labelbottom = False, bottom = False)\n",
    "ax[1,0].set_ylabel('Humidity')\n",
    "ax[0,0].set_title('Kitchen Area')\n",
    "\n",
    "ax[0,1].plot(exp_df['date'].iloc[:100,], exp_df['T2'].iloc[:100,])\n",
    "ax[0,1].tick_params(labelbottom = False, bottom = False)\n",
    "ax[1,1].plot(exp_df['date'].iloc[:100,], exp_df['RH_2'].iloc[:100,])\n",
    "ax[1,1].tick_params(labelbottom = False, bottom = False)\n",
    "ax[0,1].set_title('Living Area')\n",
    "\n",
    "ax[0,2].plot(exp_df['date'].iloc[:100,], exp_df['T3'].iloc[:100,])\n",
    "ax[0,2].tick_params(labelbottom = False, bottom = False)\n",
    "ax[1,2].plot(exp_df['date'].iloc[:100,], exp_df['RH_3'].iloc[:100,])\n",
    "ax[1,2].tick_params(labelbottom = False, bottom = False)\n",
    "ax[0,2].set_title('Laundry Area')\n",
    "\n",
    "ax[0,3].plot(exp_df['date'].iloc[:100,], exp_df['T4'].iloc[:100,])\n",
    "ax[0,3].tick_params(labelbottom = False, bottom = False)\n",
    "ax[1,3].plot(exp_df['date'].iloc[:100,], exp_df['RH_4'].iloc[:100,])\n",
    "ax[1,3].tick_params(labelbottom = False, bottom = False)\n",
    "ax[0,3].set_title('Office Area')\n",
    "\n",
    "ax[0,4].plot(exp_df['date'].iloc[:100,], exp_df['T5'].iloc[:100,])\n",
    "ax[0,4].tick_params(labelbottom = False, bottom = False)\n",
    "ax[1,4].plot(exp_df['date'].iloc[:100,], exp_df['RH_5'].iloc[:100,])\n",
    "ax[1,4].tick_params(labelbottom = False, bottom = False)\n",
    "ax[0,4].set_title('Bathroom')\n",
    "\n",
    "ax[2,0].plot(exp_df['date'].iloc[:100,], exp_df['Appliances'].iloc[:100,])\n",
    "ax[2,0].tick_params(labelbottom = False, bottom = False)\n",
    "ax[2,0].set_ylabel('Energy (Wh)')\n",
    "ax[2,0].set_title('Appliances')\n",
    "ax[3,0].plot(exp_df['date'].iloc[:100,], exp_df['lights'].iloc[:100,])\n",
    "ax[3,0].tick_params(labelbottom = False, bottom = False)\n",
    "ax[3,0].set_ylabel('Energy (Wh)')\n",
    "ax[3,0].set_title('Lights')\n",
    "ax[3,0].set_xlabel('Time (mins)')\n",
    "\n",
    "ax[2,1].plot(exp_df['date'].iloc[:100,], exp_df['T8'].iloc[:100,])\n",
    "ax[2,1].tick_params(labelbottom = False, bottom = False)\n",
    "ax[2,1].set_ylabel('Temperature')\n",
    "ax[3,1].plot(exp_df['date'].iloc[:100,], exp_df['RH_8'].iloc[:100,])\n",
    "ax[3,1].set_xlabel('Time (mins)')\n",
    "ax[3,1].set_ylabel('Humidity')\n",
    "ax[3,1].tick_params(labelbottom = False, bottom = False)\n",
    "ax[2,1].set_title('Teenager Room')\n",
    "\n",
    "ax[2,2].plot(exp_df['date'].iloc[:100,], exp_df['T3'].iloc[:100,])\n",
    "ax[2,2].tick_params(labelbottom = False, bottom = False)\n",
    "ax[3,2].plot(exp_df['date'].iloc[:100,], exp_df['RH_3'].iloc[:100,])\n",
    "ax[3,2].tick_params(labelbottom = False, bottom = False)\n",
    "ax[3,2].set_xlabel('Time (mins)')\n",
    "ax[2,2].set_title('Parents Room')\n",
    "\n",
    "ax[2,3].plot(exp_df['date'].iloc[:100,], exp_df['T6'].iloc[:100,])\n",
    "ax[2,3].tick_params(labelbottom = False, bottom = False)\n",
    "ax[3,3].plot(exp_df['date'].iloc[:100,], exp_df['RH_6'].iloc[:100,])\n",
    "ax[3,3].tick_params(labelbottom = False, bottom = False)\n",
    "ax[3,3].set_xlabel('Time (mins)')\n",
    "ax[2,3].set_title('Outside Building')\n",
    "\n",
    "ax[2,4].plot(exp_df['date'].iloc[:100,], exp_df['T7'].iloc[:100,])\n",
    "ax[2,4].tick_params(labelbottom = False, bottom = False)\n",
    "ax[3,4].plot(exp_df['date'].iloc[:100,], exp_df['RH_7'].iloc[:100,])\n",
    "ax[3,4].tick_params(labelbottom = False, bottom = False)\n",
    "ax[3,4].set_xlabel('Time (mins)')\n",
    "ax[2,4].set_title('Ironing Room')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Correlations Between Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at Temperature columns\n",
    "# regex = '^T' means starts with T\n",
    "filt = exp_df.filter(regex='^T', axis='columns').corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(filt.corr(), ax = ax)\n",
    "ax.set_title('Room Temperature Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at Relative Humidity columns\n",
    "# regex = '^R' means starts with R\n",
    "filt = exp_df.filter(regex='^R', axis='columns').corr()\n",
    "ax = plt.axes()\n",
    "sns.heatmap(filt.corr(), ax = ax)\n",
    "ax.set_title('Room Relative Humidity Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Potential Transformation Needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling mean based on last 5 values\n",
    "exp_df['rolling_mean_app'] = exp_df['Appliances'].rolling(5).mean()\n",
    "exp_df['rolling_mean_lights'] = exp_df['lights'].rolling(5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,1, figsize=(16,9))\n",
    "\n",
    "ax[0].plot(exp_df['date'], exp_df['rolling_mean_app'])\n",
    "ax[0].set_title('Appliance Rolling Mean')\n",
    "ax[0].set_ylabel('Energy (Wh)')\n",
    "ax[0].tick_params(labelbottom = False, bottom = False)\n",
    "\n",
    "ax[1].plot(exp_df['date'], exp_df['Appliances'].rolling(5).std())\n",
    "ax[1].set_title('Appliance Rolling St. Dev')\n",
    "ax[1].set_ylabel('Energy (Wh)')\n",
    "ax[1].tick_params(labelbottom = False, bottom = False)\n",
    "\n",
    "ax[2].plot(exp_df['date'], exp_df['rolling_mean_lights'])\n",
    "ax[2].set_title('Lights Rolling Mean')\n",
    "ax[2].set_ylabel('Energy (Wh)')\n",
    "ax[2].tick_params(labelbottom = False, bottom = False)\n",
    "\n",
    "ax[3].plot(exp_df['date'], exp_df['lights'].rolling(5).std())\n",
    "ax[3].set_title('Lights Rolling St. Dev')\n",
    "ax[3].set_ylabel('Energy (Wh)')\n",
    "ax[3].tick_params(labelbottom = False, bottom = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = exp_df.drop(['rolling_mean_lights', 'rolling_mean_app'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document what you have learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many basic points of interest and relationships we are able to see just from our exploratory data analysis. For example, there are no missing data points.If we did have missing data though, we would have been able to reasonably use the value of the point before; this is because the data was taken every ten minutes and the temperature and humidity do not significantly change in that time. When we look at the line graphs we can see the trends of energy usage by appliances and lights in the bottom left hand column. In the right above their graphs, we can see the temperature and relative humidity of the kitchen (chosen since many appliances are in this one room). Based on the graphs of all the rooms, we can see there is an overall spike and decline. Look more closely though, and we see these spikes and declines are not all the same. Interestingly, the graphs of the appliances and lights have a greater amount of spikes and variations then most rooms.<br/><br/>\n",
    "Upon first glance, these correlation plots reveal a few interesting things. It appears there is not as much of a correlation between temperature and the appliance and lights as there is for relative humidity and appliances and lights. <br/><br/>\n",
    "Just from these two plots, we hypothesize that relative humidity has a stronger impact on the energy usage of lights rather than appliances. On the flipside, we hypothesize temperature has a stronger impact on the energy usage of appliances than lights.   <br/><br/>\n",
    "We now must look more closely at relationships that are significant for mulitvariate timeseries forecasting. It is important to see if the data is stationary or not so we will know if we will need to apply transformations to our data. Upon first glance, it is clear the mean and standard deviation of both the appliances and the lights are not stationary - meaning their values are not maintaining a consistent value. This implies transformations will be needed in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.loc['date'] = pd.to_datetime(exp_df['date'].loc[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "from statsmodels.tsa.api import VAR, VARMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Stationarity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Augmented Dickey–Fuller test to check for stationarity.  \n",
    "\n",
    "*Null hypothesis:* If failed to be rejected, it suggests the time series is not stationary  \n",
    "*Alternative hypothesis:* The null hypothesis is rejected, it suggests the time series IS stationary.<br/><br/>\n",
    "If p-values are less than or equal to 0.05 so we can reject the null hypothesis and the data is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(col, df):\n",
    "    result = adfuller(df.values)\n",
    "    # print if not stationary\n",
    "    if result[1] > 0.05:\n",
    "        print('Non-stationary column:', col)\n",
    "        print('p-value:', result[1])\n",
    "        print('ADF Statistics:', result[0])\n",
    "        print('p-value:', result[1])\n",
    "        print('Critical values:')\n",
    "        for key, value in result[4].items():\n",
    "            print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.replace([np.inf, -np.inf], np.nan)\n",
    "exp_df.dropna(inplace=True)\n",
    "for col in exp_df.columns[1:]:\n",
    "    adf_test(col, exp_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Autocorrelation and Lag Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation is the correlation between a timeseries and the delayed version of itself. ACF is used to show the correlation coefficient against the lag and 0 means there is no correlation. The blue shading is the error bar. This shows the correlation to be at or near zero when the lag is about 25.<br/><br/>\n",
    "PACF captures a “direct” correlation between time series and a lagged version of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ACF and PACF plots\n",
    "plot_acf(exp_df['Appliances'], lags=40, title ='Appliance Autocorrelation Function (ACF)')\n",
    "plot_pacf(exp_df['Appliances'], lags=20, title ='Appliance Partial Autocorrelation Function (PACF)')\n",
    "plot_acf(exp_df['lights'],lags=40, title = 'Lights Autocorrelation Function (ACF)')\n",
    "plot_pacf(exp_df['lights'],lags=20, title='Lights Partial Autocorrelation Function (PACF)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Seasonality, Trend, Residuals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = seasonal_decompose(exp_df['Appliances'],model = 'additive',period = 360,extrapolate_trend = 'freq')\n",
    "fig = decomp.plot()\n",
    "fig.set_size_inches((16, 9))\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "decomp = seasonal_decompose(exp_df['lights'],model = 'additive',period = 360,extrapolate_trend = 'freq')\n",
    "fig = decomp.plot()\n",
    "fig.set_size_inches((16, 9))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference model due to non-stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = exp_df.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check stationarity function to make sure that there is no more remaining non-stationary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = exp_df.date\n",
    "diff_data = data.diff().dropna()\n",
    "for col in diff_data.columns[1:]:\n",
    "    adf_test(col, diff_data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used Granger Casuality to check for significant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = diff_data.columns[0]\n",
    "pred = diff_data.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for predictor in pred:\n",
    "    data = np.column_stack([diff_data[target], diff_data[predictor]])\n",
    "    gc_res = grangercausalitytests(data, maxlag=2, verbose=False)\n",
    "    results[predictor] = gc_res[2][0]['params_ftest'][1]\n",
    "\n",
    "# Print the results\n",
    "for predictor, p_value in sorted(results.items(), key=lambda x: x[1]):\n",
    "    if p_value <= 0.05:\n",
    "        print(f'{predictor}: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = diff_data.columns[1]\n",
    "pred = diff_data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for predictor in pred:\n",
    "    data = np.column_stack([diff_data[target], diff_data[predictor]])\n",
    "    gc_res = grangercausalitytests(data, maxlag=2, verbose=False)\n",
    "    results[predictor] = gc_res[2][0]['params_ftest'][1]\n",
    "\n",
    "# Print the results\n",
    "for predictor, p_value in sorted(results.items(), key=lambda x: x[1]):\n",
    "    if p_value <= 0.05:\n",
    "        print(f'{predictor}: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframes for Features to be Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_app = diff_data[['Appliances','RH_1', 'T4', 'T3', 'RH_2', 'RH_3', 'T2', 'T1', 'lights','RH_9', 'RH_6', 'RH_7', 'RH_4']]\n",
    "data_lights = diff_data[['lights', 'T4', 'RH_3', 'RH_1', 'RH_7', 'Visibility', 'T3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Hyperparameters + Make Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAR Model - Appliances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify lag value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAR(np.asarray(data_app).astype(float))\n",
    "model.select_order(20).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph with lag value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VARMAX(np.asarray(data_app).astype(float), order=(1,0), trend='n').fit(maxiter=1000)\n",
    "model.plot_diagnostics(variable=0, figsize=(13,8), lags=24)\n",
    "plt.gcf().suptitle('Industrial Production - Diagnostics', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare at Prediction with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = model.predict(start=0, end=500)\n",
    "\n",
    "plt.figure().set_figwidth(17)\n",
    "plt.plot(data_lights[1:500],color='red')\n",
    "plt.plot(predicted_result,color='blue')\n",
    "plt.title('Appliance Energy')\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='minor',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=True)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAR Model - Lights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify lag values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAR(np.asarray(data_lights).astype(float))\n",
    "model.select_order(20).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph with lag value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VARMAX(np.asarray(data_lights).astype(float), order=(1,0), trend='n').fit(maxiter=1000)\n",
    "model.plot_diagnostics(variable=0, figsize=(13,8), lags=24)\n",
    "plt.gcf().suptitle('Industrial Production - Diagnostics', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare at Prediction with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = model.predict(start=0, end=500)\n",
    "\n",
    "plt.figure().set_figwidth(17)\n",
    "plt.plot(data_lights[1:500],color='red')\n",
    "plt.plot(predicted_result,color='blue')\n",
    "plt.title('Lights Energy')\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='minor',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
